{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malariagen_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import allel\n",
    "from datetime import date\n",
    "\n",
    "import sys\n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, '/home/sanj/projects/gaardian/workflow/scripts/')\n",
    "import probetools as probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MVNcall - preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2L:28520000-28580000'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'coeae1f'\n",
    "\n",
    "cohorts = [\n",
    "    # Ag1000G phase 3 sample sets in Ag3.0\n",
    "    \"AG1000G-GH\", \n",
    "    'AG1000G-ML-A',\n",
    "     'AG1000G-BF-A',\n",
    "     'AG1000G-BF-B',\n",
    "     'AG1000G-GN-A',\n",
    "     'AG1000G-GN-B',\n",
    "    'AG1000G-TZ',\n",
    "    # Amenta-Etego sample sets in Ag3.3\n",
    "    # GAARDIAN sample set in Ag3.4\n",
    "    '1244-VO-GH-YAWSON-VMF00149',\n",
    "    # GAARD Ghana sample set in Ag3.2\n",
    "     \"1244-VO-GH-YAWSON-VMF00051\",\n",
    "     '1245-VO-CI-CONSTANT-VMF00054',\n",
    "     '1253-VO-TG-DJOGBENOU-VMF00052',\n",
    "     '1237-VO-BJ-DJOGBENOU-VMF00050'\n",
    "]\n",
    "\n",
    "\n",
    "contig = '2L'\n",
    "start = 28_520_000\n",
    "end = 28_580_000\n",
    "\n",
    "region = f\"{contig}:{start}-{end}\"\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ag3 = malariagen_data.Ag3(pre=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SNP calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = ag3.snp_calls(region=region, sample_sets=cohorts)\n",
    "\n",
    "ac = allel.GenotypeArray(calls['call_genotype']).count_alleles()\n",
    "seg = ac.is_segregating()\n",
    "\n",
    "calls = calls.sel(variants=seg)\n",
    "alleles = calls['variant_allele'].compute()\n",
    "geno = allel.GenotypeArray(calls['call_genotype'])\n",
    "pos = allel.SortedIndex(calls['variant_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71195c106e5c474ab805ffce5a5028f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load sample metadata:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312ff2b055fc49fea11f1551586e1397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load SNP genotypes:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651d28e582fc443698f6d6cf45c77d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute allele frequencies:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9f3071cb5f4ca0967253ddfb83a405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute SNP effects:   0%|          | 0/7629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonsynons = np.array([])\n",
    "for i in range(27,28):\n",
    "    if i == 30: continue\n",
    "    transcript_id = f\"AGAP0062{i}-RA\"\n",
    "    \n",
    "    snp_allele_freqs_df = ag3.snp_allele_frequencies(\n",
    "        transcript=transcript_id, \n",
    "        cohorts=\"admin1_year\", \n",
    "        sample_sets=cohorts, \n",
    "        drop_invariant=False,\n",
    "    )\n",
    "    df = snp_allele_freqs_df.query(\"max_af > 0.05 & effect == 'NON_SYNONYMOUS_CODING'\")\n",
    "    nonsynons = np.append(nonsynons, df.reset_index().loc[:, 'position'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = ag3.sample_metadata(sample_sets=cohorts)\n",
    "\n",
    "gl_mapping = {'0/0':0, \n",
    "                  '0/1':1, \n",
    "                  '1/1':2, \n",
    "                  '0/2':3, \n",
    "                  '1/2':4, \n",
    "                  \"2/2\":5, \n",
    "                  '0/3':6, \n",
    "                  '1/3':7, \n",
    "                  '2/3':8, \n",
    "                  '3/3':9}\n",
    "\n",
    "def code_genotype_likelihoods(genotype, gl_mapping):\n",
    "        \n",
    "    gl = np.repeat(25, 10).astype(str)\n",
    "    if genotype == './.':\n",
    "        return(','.join(gl))\n",
    "    \n",
    "    gl[gl_mapping[genotype]] = 0\n",
    "    \n",
    "    return(','.join(gl))\n",
    "\n",
    "\n",
    "def write_vcf_header(vcf_file, contig):\n",
    "    \"\"\"\n",
    "    Writes a VCF header.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('##fileformat=VCFv4.1', file=vcf_file)\n",
    "    # write today's date\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    print('##fileDate=%s' % today, file=vcf_file)\n",
    "    # write source\n",
    "    print('##source=scikit-allel-%s + ZarrToVCF.py' % allel.__version__, file=vcf_file)\n",
    "    #write refs and contigs \n",
    "    print('##reference=resources/reference/Anopheles-gambiae-PEST_CHROMOSOMES_AgamP4.fa', file=vcf_file)\n",
    "    print('##contig=<ID=2R,length=61545105>', file=vcf_file) if contig == '2R' else None\n",
    "    print('##contig=<ID=3R,length=53200684>', file=vcf_file) if contig == '3R' else None \n",
    "    print('##contig=<ID=2L,length=49364325>', file=vcf_file) if contig == '2L' else None\n",
    "    print('##contig=<ID=3L,length=41963435>', file=vcf_file) if contig == '3L' else None\n",
    "    print('##contig=<ID=X,length=24393108>', file=vcf_file) if contig == 'X' else None\n",
    "    print('##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">', file=vcf_file)\n",
    "    print(\"##FORMAT=<ID=PL,Number=.,Type=Integer,Description='Phred-scaled Genotype Likelihoods'>\", file=vcf_file)\n",
    "\n",
    "\n",
    "def GenoToPandasToVCF(vcf_file, geno, positions, alleles, contig, nchunks=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts genotype and POS arrays to vcf, using pd dataframes in chunks. \n",
    "    Segregating sites only. Needs REF and ALT arrays.\n",
    "    \"\"\"\n",
    "    refs = alleles[:,0]\n",
    "    alts = alleles[:,1:]\n",
    "    refs = refs.astype(str)\n",
    "    alts = [a +\",\" + b + \",\" + c for a,b,c in alts.values.astype(str)]\n",
    "\n",
    "    probe.log(\"calculating chunks sizes...\")\n",
    "    chunks = np.round(np.arange(0, geno.shape[0], geno.shape[0]/nchunks)).astype(int).tolist()\n",
    "    chunks.append(geno.shape[0])\n",
    "\n",
    "    for idx, chunk in enumerate(chunks[:-1]):\n",
    "\n",
    "        gn = geno[chunks[idx]:chunks[idx+1]]\n",
    "        pos = positions[chunks[idx]:chunks[idx+1]]\n",
    "        ref = refs[chunks[idx]:chunks[idx+1]]\n",
    "        alt = alts[chunks[idx]:chunks[idx+1]]\n",
    "        \n",
    "        # Contruct SNP info DF\n",
    "        vcf_df = pd.DataFrame({'#CHROM': contig,\n",
    "                 'POS': pos,\n",
    "                 'ID': '.',\n",
    "                 'REF': ref,\n",
    "                 'ALT': alt,\n",
    "                 'QUAL': '.',\n",
    "                 'FILTER': '.',\n",
    "                 'INFO':'.',\n",
    "                'FORMAT': 'GT:PL'})\n",
    "\n",
    "        probe.log(f\"Pandas SNP info DataFrame constructed...{idx}\")\n",
    "\n",
    "        # Geno to VCF\n",
    "        vcf = pd.DataFrame(gn.to_gt().astype(str), columns=metadata['sample_id'])\n",
    "        gl_df = vcf.applymap(lambda x: code_genotype_likelihoods(x, gl_mapping))\n",
    "        vcf = vcf + \":\" + gl_df\n",
    "        \n",
    "        probe.log(\"Concatenating info and genotype dataframes...\")\n",
    "        vcf = pd.concat([vcf_df, vcf], axis=1)\n",
    "\n",
    "        probe.log(f\"Pandas Genotype data constructed...{idx}\")\n",
    "\n",
    "        if (idx==0) is True:\n",
    "            with open(f\"{vcf_file}\", 'w') as vcfheader:\n",
    "                    write_vcf_header(vcfheader, contig)\n",
    "\n",
    "        probe.log(\"Writing to .vcf\")\n",
    "\n",
    "        vcf.to_csv(vcf_file, \n",
    "                   sep=\"\\t\", \n",
    "                   index=False,\n",
    "                   mode='a',\n",
    "                  header=(idx==0), \n",
    "                  line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bool = pos.locate_intersection(nonsynons)\n",
    "geno = geno.compress(pos_bool[0], axis=0)\n",
    "alleles = alleles[pos_bool[0]]\n",
    "pos = pos[pos_bool[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the non-synon SNPs to be ones that are not present in the haplotype data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "haps = ag3.haplotypes(region=region, sample_sets=cohorts, analysis='gamb_colu_arab')\n",
    "haps_pos = haps['variant_position'].compute().values\n",
    "pos_inhaps_bool = np.isin(pos, haps_pos)\n",
    "geno = geno.compress(~pos_inhaps_bool, axis=0)\n",
    "pos = pos[~pos_inhaps_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating chunks sizes...\n",
      "Pandas SNP info DataFrame constructed...0\n",
      "Concatenating info and genotype dataframes...\n",
      "Pandas Genotype data constructed...0\n",
      "Writing to .vcf\n",
      "Pandas SNP info DataFrame constructed...1\n",
      "Concatenating info and genotype dataframes...\n",
      "Pandas Genotype data constructed...1\n",
      "Writing to .vcf\n",
      "Pandas SNP info DataFrame constructed...2\n",
      "Concatenating info and genotype dataframes...\n",
      "Pandas Genotype data constructed...2\n",
      "Writing to .vcf\n",
      "Pandas SNP info DataFrame constructed...3\n",
      "Concatenating info and genotype dataframes...\n",
      "Pandas Genotype data constructed...3\n",
      "Writing to .vcf\n"
     ]
    }
   ],
   "source": [
    "vcf_df = GenoToPandasToVCF(f\"../../results/phasing/{dataset}.genotypes.vcf\", geno, pos, alleles, contig='2L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GL : genotype likelihoods comprised of comma separated floating point log10-scaled likelihoods for all possible\n",
    "genotypes given the set of alleles defined in the REF and ALT fields. In presence of the GT field the same\n",
    "ploidy is expected and the canonical order is used; without GT field, diploidy is assumed. If A is the allele in\n",
    "REF and B,C,... are the alleles as ordered in ALT, the ordering of genotypes for the likelihoods is given by:\n",
    "F(j/k) = (k*(k+1)/2)+j. In other words, for biallelic sites the ordering is: AA,AB,BB; for triallelic sites the\n",
    "ordering is: AA,AB,BB,AC,BC,CC, etc. For example: GT:GL 0/1:-323.03,-99.29,-802.53 (Floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_df = vcf_df.applymap(lambda x: code_genotype_likelihoods(x, gl_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25,25,25,25,25,25,25,0,25,25'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_genotype_likelihoods(\"1/3\", gl_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaffolds file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id_order_vcf = metadata['sample_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "haps = ag3.haplotypes(region=region, sample_sets=cohorts, analysis='gamb_colu_arab')\n",
    "sample_id_order_haps = haps['sample_id'].compute().values\n",
    "bool_ = np.isin(sample_id_order_haps, sample_id_order_vcf)\n",
    "hap_ac = allel.GenotypeArray(haps['call_genotype']).count_alleles()\n",
    "hap_seg = hap_ac.is_segregating()\n",
    "haps = haps.sel(variants=hap_seg,samples=bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = haps['variant_allele'].compute().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([\"SNP\" + a for a in haps['variant_position'].values.astype(str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "haps_df = pd.DataFrame({'#CHROM': contig,\n",
    "        'ID': ids,\n",
    "        'POS': haps['variant_position'].values,\n",
    "        'REF': alleles[:,0],\n",
    "        'ALT': alleles[:,1]})\n",
    "        \n",
    "haps_geno = allel.GenotypeArray(haps['call_genotype']).to_haplotypes()\n",
    "\n",
    "haps_geno_df = pd.DataFrame(haps_geno)\n",
    "allhaps = pd.concat([haps_df, haps_geno_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(haps['sample_id'].values).to_csv(f\"results/phasing/{dataset}.sample\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "allhaps.to_csv(f\"results/phasing/{dataset}.haps\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#CHROM</th>\n",
       "      <th>ID</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>4396</th>\n",
       "      <th>4397</th>\n",
       "      <th>4398</th>\n",
       "      <th>4399</th>\n",
       "      <th>4400</th>\n",
       "      <th>4401</th>\n",
       "      <th>4402</th>\n",
       "      <th>4403</th>\n",
       "      <th>4404</th>\n",
       "      <th>4405</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28520002</td>\n",
       "      <td>28520002</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28520008</td>\n",
       "      <td>28520008</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28520016</td>\n",
       "      <td>28520016</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28520017</td>\n",
       "      <td>28520017</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28520022</td>\n",
       "      <td>28520022</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28579975</td>\n",
       "      <td>28579975</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12064</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28579976</td>\n",
       "      <td>28579976</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28579986</td>\n",
       "      <td>28579986</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28579991</td>\n",
       "      <td>28579991</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>2L</td>\n",
       "      <td>SNP28579999</td>\n",
       "      <td>28579999</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12068 rows × 4411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #CHROM           ID       POS REF ALT  0  1  2  3  4  ...  4396  4397  \\\n",
       "0         2L  SNP28520002  28520002   C   T  0  0  0  0  0  ...     0     0   \n",
       "1         2L  SNP28520008  28520008   A   G  1  1  1  1  0  ...     0     0   \n",
       "2         2L  SNP28520016  28520016   A   C  0  0  0  0  0  ...     0     0   \n",
       "3         2L  SNP28520017  28520017   G   A  0  0  0  0  0  ...     0     0   \n",
       "4         2L  SNP28520022  28520022   T   C  0  0  0  0  0  ...     0     0   \n",
       "...      ...          ...       ...  ..  .. .. .. .. .. ..  ...   ...   ...   \n",
       "12063     2L  SNP28579975  28579975   C   T  0  0  0  0  0  ...     0     0   \n",
       "12064     2L  SNP28579976  28579976   G   T  0  0  0  0  0  ...     1     0   \n",
       "12065     2L  SNP28579986  28579986   C   T  0  0  0  0  0  ...     0     0   \n",
       "12066     2L  SNP28579991  28579991   G   A  0  0  0  0  0  ...     0     0   \n",
       "12067     2L  SNP28579999  28579999   G   A  0  0  0  0  0  ...     0     0   \n",
       "\n",
       "       4398  4399  4400  4401  4402  4403  4404  4405  \n",
       "0         0     0     0     0     0     0     0     0  \n",
       "1         0     1     1     1     1     1     1     1  \n",
       "2         0     0     0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "12063     0     0     0     0     0     0     0     0  \n",
       "12064     1     0     0     0     0     0     0     0  \n",
       "12065     0     0     0     0     0     0     0     0  \n",
       "12066     0     0     0     0     0     0     0     0  \n",
       "12067     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[12068 rows x 4411 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allhaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "710100144729ec1057471750b60f3250df4296be7eb29e7e87fec32ed718ec4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
