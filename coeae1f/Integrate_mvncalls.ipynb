{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238eeb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import allel\n",
    "import malariagen_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import locusPocus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad3f9e",
   "metadata": {},
   "source": [
    "### Integrating the mvncall phasing into the biallelic haplotypes\n",
    "A function which -\n",
    "\n",
    "- returns an allel.HaplotypeArray or Haplotype Xarray for the region\n",
    "- returns a pd.DataFrame with the same data\n",
    "- haplotypes ordered by ag3.haplotypes() order\n",
    "- snps ordered by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913e81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Coeae1f'\n",
    "\n",
    "cohorts = [\n",
    "    # Ag1000G phase 3 sample sets in Ag3.0\n",
    "    \"AG1000G-GH\", \n",
    "    'AG1000G-ML-A',\n",
    "     'AG1000G-BF-A',\n",
    "     'AG1000G-BF-B',\n",
    "     'AG1000G-GN-A',\n",
    "     'AG1000G-GN-B',\n",
    "    'AG1000G-TZ',\n",
    "    # Amenta-Etego sample sets in Ag3.3\n",
    "    # GAARDIAN sample set in Ag3.4\n",
    "    '1244-VO-GH-YAWSON-VMF00149',\n",
    "    # GAARD Ghana sample set in Ag3.2\n",
    "     \"1244-VO-GH-YAWSON-VMF00051\",\n",
    "     '1245-VO-CI-CONSTANT-VMF00054',\n",
    "     '1253-VO-TG-DJOGBENOU-VMF00052',\n",
    "     '1237-VO-BJ-DJOGBENOU-VMF00050'\n",
    "]\n",
    "\n",
    "\n",
    "contig = '2L'\n",
    "start = 28_520_000\n",
    "end = 28_570_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ec7c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ag3 = malariagen_data.Ag3(pre=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d0d29",
   "metadata": {},
   "source": [
    "Load VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dc7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiallelic_haplotypes(cohorts, path_to_multi_vcf, contig, start, end, non_synon_only=True, remove_invariant=True):\n",
    "    \"\"\"\n",
    "    Load and integrate mvncalls into haplotype data\n",
    "    \"\"\"\n",
    "    \n",
    "    vcf = allel.read_vcf(path_to_multi_vcf, \n",
    "                     fields=['samples', 'variants/ALT', 'variants/CHROM', 'calldata/GT', 'variants/POS', 'variants/QUAL', 'variants/REF'])\n",
    "    \n",
    "    print(\"Phased mvncall data has shape: \", vcf['calldata/GT'].shape)\n",
    "    \n",
    "    haps = ag3.haplotypes(region=f\"{contig}:{start}-{end}\", sample_sets=cohorts, analysis='gamb_colu_arab')\n",
    "    \n",
    "    geno_bial = allel.GenotypeArray(haps['call_genotype'])\n",
    "    pos_bial = allel.SortedIndex(haps['variant_position'].values)    \n",
    "    geno_multi = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "    pos_multi = allel.SortedIndex(vcf['variants/POS'])   \n",
    "    \n",
    "    assert (vcf['samples'] == haps['sample_id'].values).all(), \"VCF and haps sample order do not match\"\n",
    "    \n",
    "    multi_df = pd.DataFrame(geno_multi.to_haplotypes()).set_index(pos_multi.values)\n",
    "    bial_df = pd.DataFrame(geno_bial.to_haplotypes()).set_index(pos_bial.values)\n",
    "    haps_df = pd.concat([multi_df, bial_df], axis=0)\n",
    "    haps_df = haps_df.sort_index()\n",
    "    \n",
    "    pos = allel.SortedIndex(np.sort(np.concatenate([pos_multi.values, pos_bial.values])))\n",
    "    \n",
    "    if non_synon_only:       \n",
    "        print(\"Returning only non-synonymous SNPs\")\n",
    "        transcripts = ag3.geneset().query(\"type == 'exon' & contig == @contig & start > @start & end < @end\")['Parent'].unique()\n",
    "        \n",
    "        snp_freq_dfs = []\n",
    "        for transcript_id in transcripts:\n",
    "            snp_allele_freqs_df = ag3.snp_allele_frequencies(\n",
    "                transcript=transcript_id, \n",
    "                cohorts=\"admin1_year\", \n",
    "                sample_sets=cohorts, \n",
    "                drop_invariant=False,\n",
    "            )\n",
    "            snp_freq_dfs.append(snp_allele_freqs_df)\n",
    "        snp_freq_df = pd.concat(snp_freq_dfs).query(\"effect == 'NON_SYNONYMOUS_CODING' & max_af > 0.05\")\n",
    "        aa_df = snp_freq_df.reset_index()[['position', 'aa_change']]\n",
    "        aa_df = aa_df.groupby('position').agg({'aa_change': '_'.join}).reset_index()\n",
    "        pos_bool, aa_bool = pos.locate_intersection(aa_df['position'])\n",
    "        pos = pos[pos_bool]\n",
    "        haps_df = haps_df[pos_bool]\n",
    "        haps_df = haps_df.set_index(aa_df[aa_bool]['aa_change'], append=True)\n",
    "        if remove_invariant:\n",
    "            invariant_cols = haps_df.nunique(axis=1) <= 1\n",
    "            print(f\"Removing {invariant_cols.sum()} invariant SNPs\")\n",
    "            haps_df = haps_df.loc[~invariant_cols, :]\n",
    "            print(f\"There are {haps_df.shape[1]} haplotypes and {haps_df.shape[0]} segregating haplotype calls\")\n",
    "    \n",
    "    return(allel.HaplotypeArray(haps_df.values), haps_df, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b354451",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_multi_vcf = \"../../results/phasing/coeae1f.phasedMulti.vcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d1dd1",
   "metadata": {},
   "source": [
    "### getting appropriate aa changes for multialleles\n",
    "\n",
    "- We have biallelic haplotype arrays\n",
    "- We have a multiallelic haplotype array \n",
    "\n",
    "- We have to recode the biallelic arrays in order to find the appropriate aa change\n",
    "- We also need to split multialleles onto different rows, with appropriate aa change \n",
    "- Then join them all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02bf6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:1743: UserWarning: invalid FORMAT header: \"##FORMAT=<ID=GT,Number=1,Type=String,Description='Genotype'>\\n\"\n",
      "  warnings.warn('invalid FORMAT header: %r' % header)\n",
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:1732: UserWarning: invalid INFO header: \"##INFO=<ID=NUMALT,Number=1,Type=Integer,Description='Number of alternative alleles'>\\n\"\n",
      "  warnings.warn('invalid INFO header: %r' % header)\n",
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:1732: UserWarning: invalid INFO header: \"##INFO=<ID=AVGPOST,Number=1,Type=Float,Description='Average posterior probability from MVNcall'>\\n\"\n",
      "  warnings.warn('invalid INFO header: %r' % header)\n",
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:1743: UserWarning: invalid FORMAT header: \"##FORMAT=<ID=PL,Number=.,Type=Integer,Description='Phred-scaled Genotype Likelihoods'>\\n\"\n",
      "  warnings.warn('invalid FORMAT header: %r' % header)\n",
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:1248: UserWarning: 'GT' FORMAT header not found\n",
      "  warnings.warn('%r FORMAT header not found' % name)\n",
      "/home/sanj/apps/anaconda3/lib/python3.7/site-packages/allel/io/vcf_read.py:322: UserWarning: more samples than given in header; field: CALLDATA; variant: 0 (2\u0000:28546251); sample: 2431:0 (unknown:GT)\n",
      "  chunks = [d[0] for d in it]\n"
     ]
    }
   ],
   "source": [
    "vcf = allel.read_vcf(\"../../results/phasing/coeae1f.phasedMulti.vcf\", fields=['samples', 'variants/ALT', 'variants/CHROM', 'calldata/GT', 'variants/POS', 'variants/QUAL', 'variants/REF'])\n",
    "haps = ag3.haplotypes(region=f\"{contig}:{start}-{end}\", sample_sets=cohorts, analysis='gamb_colu_arab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a45dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_bial = allel.GenotypeArray(haps['call_genotype'])\n",
    "pos_bial = allel.SortedIndex(haps['variant_position'].values)    \n",
    "geno_multi = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "pos_multi = allel.SortedIndex(vcf['variants/POS'])   \n",
    "\n",
    "assert (vcf['samples'] == haps['sample_id'].values).all(), \"VCF and haps sample order do not match\"\n",
    "\n",
    "multi_df = pd.DataFrame(geno_multi.to_haplotypes()).set_index(pos_multi.values)\n",
    "bial_df = pd.DataFrame(geno_bial.to_haplotypes()).set_index(pos_bial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "093a6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = pd.concat([multi_df, multi_df]).apply(lambda x: pd.unique(x), axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ae2b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alleles = multi_df.apply(lambda x: pd.unique(x), axis=1)\n",
    "\n",
    "def split_multialleles(multi_df):\n",
    "    #alleles = multi_df.apply(lambda x: pd.unique(x), axis=1)\n",
    "    df2 = multi_df.copy()\n",
    "    df2.index = [28_545_700]\n",
    "    alleles = pd.concat([multi_df, df2]).apply(lambda x: pd.unique(x), axis=1)\n",
    "    \n",
    "    df_list = []\n",
    "    for idx, multi_allele in multi_df.iterrows():\n",
    "        if len(alleles.loc[idx]) == 2:\n",
    "            print(f\"only two alleles = {idx}\")\n",
    "            return(df_list.append(multi_allele.to_frame()))\n",
    "        \n",
    "        multi_allele1 = multi_allele.copy()\n",
    "        multi_allele2 = multi_allele.copy()\n",
    "\n",
    "        multi_allele2[multi_allele2 == alleles[idx][1]] = 0\n",
    "        multi_allele1[multi_allele1 == alleles[idx][2]] = 0 \n",
    "\n",
    "        df_list.append(pd.concat([multi_allele1, multi_allele2], axis=1).T)\n",
    "\n",
    "    return(pd.concat(df_list, axis=1))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcb83539",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_split_df = split_multialleles(multi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c380f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_array = allel.HaplotypeArray(bial_df.values)\n",
    "hap_positions = allel.SortedIndex(bial_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e17985d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = ag3.geneset().query(\"type == 'exon' & contig == @contig & start > @start & end < @end\")['Parent'].unique()\n",
    "\n",
    "snp_freq_dfs = []\n",
    "for transcript_id in transcripts:\n",
    "    snp_allele_freqs_df = ag3.snp_effects(\n",
    "        transcript=transcript_id, \n",
    "    )\n",
    "    snp_freq_dfs.append(snp_allele_freqs_df)\n",
    "\n",
    "df_effects = pd.concat(snp_freq_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d33329",
   "metadata": {},
   "source": [
    "We first remap the alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ca752f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_array = allel.HaplotypeArray(bial_df.values)\n",
    "hap_positions = allel.SortedIndex(bial_df.index.values)\n",
    "\n",
    "haps_remapped, remap_pos = locusPocus.remap_haplo_alleles(hap_array, \n",
    "                                        hap_positions, \n",
    "                                        transcript=f\"{contig}:{start}-{end}\", \n",
    "                                        sample_set=cohorts, \n",
    "                                        metaquery=None)\n",
    "\n",
    "bial_df = pd.DataFrame(haps_remapped).set_index(remap_pos.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fae13d",
   "metadata": {},
   "source": [
    "After remapping, we need to join this to our split multiallelic sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9d9965dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "haps_df = pd.concat([bial_df, multi_split_df], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc6582",
   "metadata": {},
   "source": [
    "Load df_effects dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "49438d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4852</th>\n",
       "      <th>4853</th>\n",
       "      <th>4854</th>\n",
       "      <th>4855</th>\n",
       "      <th>4856</th>\n",
       "      <th>4857</th>\n",
       "      <th>4858</th>\n",
       "      <th>4859</th>\n",
       "      <th>4860</th>\n",
       "      <th>4861</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28546251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28546251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "28546251     0     0     0     0     2     2     0     0     0     0  ...   \n",
       "28546251     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "          4852  4853  4854  4855  4856  4857  4858  4859  4860  4861  \n",
       "28546251     2     2     0     2     0     0     0     0     0     0  \n",
       "28546251     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 4862 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myalt = 28546251\n",
    "haps_df.loc[myalt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "06a873c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_bool = haps_df.apply(lambda x: len(np.unique(x)) > 1, axis=1)\n",
    "haps_df = haps_df[seg_bool]\n",
    "\n",
    "pos = allel.SortedIndex(haps_df.index.values)\n",
    "hap_pos_bool, df_effects_bool = pos.locate_intersection(df_effects['position'])\n",
    "df_effects = df_effects[df_effects_bool]\n",
    "hap_remap_positions = pos[hap_pos_bool]\n",
    "haps_df = haps_df[hap_pos_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d60136c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "aa_change_list = []\n",
    "non_synon_bool= []\n",
    "for pos, row in haps_df.iterrows():\n",
    "    if pos == 28546251:\n",
    "        print(\"yay\")\n",
    "    df_eff = df_effects.query(\"position == @pos\")\n",
    "    alleles = np.unique(row)\n",
    "    alt = alleles[1]-1\n",
    "    \n",
    "    eff = df_eff['effect'].to_numpy()[alt]\n",
    "    if eff != 'NON_SYNONYMOUS_CODING':\n",
    "        aa_change = \"\"\n",
    "        non_synon_bool.append(False)\n",
    "    elif eff == 'NON_SYNONYMOUS_CODING':\n",
    "        aa_change = df_eff['aa_change'].to_numpy()[alt]\n",
    "        non_synon_bool.append(True)\n",
    "\n",
    "    aa_change_list.append(aa_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090837b",
   "metadata": {},
   "source": [
    "There are still intronic SNPs with no aa change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "67eeb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "haps_df.loc[:, 'aa_change'] = aa_change_list\n",
    "\n",
    "haps_df = haps_df.set_index(\"aa_change\", append=True)\n",
    "\n",
    "haps_df = haps_df[non_synon_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f04a05d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4852</th>\n",
       "      <th>4853</th>\n",
       "      <th>4854</th>\n",
       "      <th>4855</th>\n",
       "      <th>4856</th>\n",
       "      <th>4857</th>\n",
       "      <th>4858</th>\n",
       "      <th>4859</th>\n",
       "      <th>4860</th>\n",
       "      <th>4861</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_change</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E477V</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "aa_change                                                              ...   \n",
       "E477V         0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "           4852  4853  4854  4855  4856  4857  4858  4859  4860  4861  \n",
       "aa_change                                                              \n",
       "E477V         0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[1 rows x 4862 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haps_df.loc[28545767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "059aefa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4852</th>\n",
       "      <th>4853</th>\n",
       "      <th>4854</th>\n",
       "      <th>4855</th>\n",
       "      <th>4856</th>\n",
       "      <th>4857</th>\n",
       "      <th>4858</th>\n",
       "      <th>4859</th>\n",
       "      <th>4860</th>\n",
       "      <th>4861</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aa_change</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28520016</th>\n",
       "      <th>E122A</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28520022</th>\n",
       "      <th>L124S</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28520028</th>\n",
       "      <th>H126R</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28520039</th>\n",
       "      <th>S130R</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28520069</th>\n",
       "      <th>V140I</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569873</th>\n",
       "      <th>S922F</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569877</th>\n",
       "      <th>P921S</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569879</th>\n",
       "      <th>R920H</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569883</th>\n",
       "      <th>N919H</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569976</th>\n",
       "      <th>F913C</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2403 rows × 4862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1     2     3     4     5     6     7     8     \\\n",
       "         aa_change                                                         \n",
       "28520016 E122A         0     0     0     0     0     0     0     0     0   \n",
       "28520022 L124S         0     0     0     0     0     0     0     0     0   \n",
       "28520028 H126R         0     0     0     0     0     0     0     0     0   \n",
       "28520039 S130R         0     0     0     0     0     0     0     0     0   \n",
       "28520069 V140I         0     0     0     0     0     0     0     0     0   \n",
       "...                  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "28569873 S922F         0     0     0     0     0     0     0     0     0   \n",
       "28569877 P921S         0     0     0     0     0     0     0     0     0   \n",
       "28569879 R920H         0     0     0     0     0     0     0     0     0   \n",
       "28569883 N919H         0     0     0     0     0     0     0     0     0   \n",
       "28569976 F913C         0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "                    9     ...  4852  4853  4854  4855  4856  4857  4858  4859  \\\n",
       "         aa_change        ...                                                   \n",
       "28520016 E122A         0  ...     0     0     0     0     0     0     0     0   \n",
       "28520022 L124S         0  ...     0     0     0     0     0     0     0     0   \n",
       "28520028 H126R         0  ...     0     0     0     0     0     0     0     0   \n",
       "28520039 S130R         0  ...     0     0     0     0     0     0     0     0   \n",
       "28520069 V140I         0  ...     0     0     0     0     0     0     0     0   \n",
       "...                  ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "28569873 S922F         0  ...     0     0     0     0     0     0     0     0   \n",
       "28569877 P921S         0  ...     0     0     0     0     0     0     0     0   \n",
       "28569879 R920H         0  ...     0     0     0     0     0     0     0     0   \n",
       "28569883 N919H         0  ...     0     0     0     0     0     0     0     0   \n",
       "28569976 F913C         0  ...     0     0     0     0     0     0     0     0   \n",
       "\n",
       "                    4860  4861  \n",
       "         aa_change              \n",
       "28520016 E122A         0     0  \n",
       "28520022 L124S         0     0  \n",
       "28520028 H126R         0     0  \n",
       "28520039 S130R         0     0  \n",
       "28520069 V140I         0     0  \n",
       "...                  ...   ...  \n",
       "28569873 S922F         0     0  \n",
       "28569877 P921S         0     0  \n",
       "28569879 R920H         0     0  \n",
       "28569883 N919H         0     0  \n",
       "28569976 F913C         0     0  \n",
       "\n",
       "[2403 rows x 4862 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "37e1f25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4852</th>\n",
       "      <th>4853</th>\n",
       "      <th>4854</th>\n",
       "      <th>4855</th>\n",
       "      <th>4856</th>\n",
       "      <th>4857</th>\n",
       "      <th>4858</th>\n",
       "      <th>4859</th>\n",
       "      <th>4860</th>\n",
       "      <th>4861</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28546251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "28546251     0     0     0     0     2     2     0     0     0     0  ...   \n",
       "\n",
       "          4852  4853  4854  4855  4856  4857  4858  4859  4860  4861  \n",
       "28546251     2     2     0     2     0     0     0     0     0     0  \n",
       "\n",
       "[1 rows x 4862 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5f95dc5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotypes loaded\n"
     ]
    }
   ],
   "source": [
    "vcf = allel.read_vcf(path_to_multi_vcf, fields=['samples', 'variants/ALT', 'variants/CHROM', 'calldata/GT', 'variants/POS', 'variants/QUAL', 'variants/REF'])\n",
    "haps = ag3.haplotypes(region=f\"{contig}:{start}-{end}\", sample_sets=cohorts, analysis=\"gamb_colu_arab\")\n",
    "\n",
    "print(\"Genotypes loaded\")\n",
    "haps_bial = allel.GenotypeArray(haps['call_genotype']).to_haplotypes()\n",
    "pos_bial = allel.SortedIndex(haps['variant_position'].values)    \n",
    "haps_multi = allel.GenotypeArray(vcf['calldata/GT']).to_haplotypes()\n",
    "pos_multi = allel.SortedIndex(vcf['variants/POS'])   \n",
    "\n",
    "assert (vcf['samples'] == haps['sample_id'].values).all(), \"VCF and haps sample order do not match\"\n",
    "\n",
    "multi_df = pd.DataFrame(haps_multi).set_index(pos_multi.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f1a311db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 2, 1]\n",
       "Name: 28545677, dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_multialleles(multi_df).loc[28545677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565dc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "16e05d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only two alleles = 28545862\n",
      "only two alleles = 28545945\n",
      "only two alleles = 28546024\n",
      "only two alleles = 28546029\n",
      "only two alleles = 28546185\n",
      "only two alleles = 28546335\n",
      "only two alleles = 28546340\n",
      "only two alleles = 28546376\n",
      "only two alleles = 28546460\n",
      "only two alleles = 28546587\n",
      "only two alleles = 28546588\n",
      "only two alleles = 28546589\n",
      "only two alleles = 28546634\n",
      "only two alleles = 28546656\n",
      "only two alleles = 28546660\n",
      "only two alleles = 28546810\n",
      "only two alleles = 28547166\n",
      "only two alleles = 28547522\n",
      "only two alleles = 28547729\n",
      "only two alleles = 28547744\n",
      "only two alleles = 28547759\n",
      "only two alleles = 28547780\n"
     ]
    }
   ],
   "source": [
    "alleles = multi_df.apply(lambda x: pd.unique(x), axis=1).to_frame()\n",
    "\n",
    "df_list = []\n",
    "for idx, multi_allele in multi_df.iterrows():\n",
    "    if len(alleles.loc[idx][0]) == 2:\n",
    "        print(f\"only two alleles = {idx}\")\n",
    "        df_list.append(multi_allele.to_frame().T)\n",
    "    else:\n",
    "        multi_allele1 = multi_allele.copy()\n",
    "        multi_allele2 = multi_allele.copy()\n",
    "\n",
    "        multi_allele2[multi_allele2 == alleles.loc[idx][0][1]] = 0\n",
    "        multi_allele1[multi_allele1 == alleles.loc[idx][0][2]] = 0 \n",
    "        df_list.append(pd.concat([multi_allele1, multi_allele2], axis=1).T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "4ce07c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_multialleles(multi_df):\n",
    "    alleles = multi_df.apply(lambda x: pd.unique(x), axis=1).to_frame()\n",
    "    \n",
    "    df_list = []\n",
    "    for idx, multi_allele in multi_df.iterrows():\n",
    "        if len(alleles.loc[idx][0]) == 2:\n",
    "            print(f\"only two alleles = {idx}\")\n",
    "            df_list.append(multi_allele.to_frame().T)\n",
    "        else:\n",
    "            multi_allele1 = multi_allele.copy()\n",
    "            multi_allele2 = multi_allele.copy()\n",
    "\n",
    "            multi_allele2[multi_allele2 == alleles.loc[idx][0][1]] = 0\n",
    "            multi_allele1[multi_allele1 == alleles.loc[idx][0][2]] = 0 \n",
    "\n",
    "            df_list.append(pd.concat([multi_allele1, multi_allele2], axis=1).T)\n",
    "\n",
    "    return(pd.concat(df_list, axis=0))\n",
    "\n",
    "\n",
    "def load_multiallelic_haplotypes(path_to_multi_vcf, sample_sets ,contig, start, end, analysis='gamb_colu_arab', metaquery=None):\n",
    "    vcf = allel.read_vcf(path_to_multi_vcf, fields=['samples', 'variants/ALT', 'variants/CHROM', 'calldata/GT', 'variants/POS', 'variants/QUAL', 'variants/REF'])\n",
    "    haps = ag3.haplotypes(region=f\"{contig}:{start}-{end}\", sample_sets=sample_sets, analysis=analysis)\n",
    "    \n",
    "    print(\"Genotypes loaded\")\n",
    "    haps_bial = allel.GenotypeArray(haps['call_genotype']).to_haplotypes()\n",
    "    pos_bial = allel.SortedIndex(haps['variant_position'].values)    \n",
    "    haps_multi = allel.GenotypeArray(vcf['calldata/GT']).to_haplotypes()\n",
    "    pos_multi = allel.SortedIndex(vcf['variants/POS'])   \n",
    "\n",
    "    assert (vcf['samples'] == haps['sample_id'].values).all(), \"VCF and haps sample order do not match\"\n",
    "\n",
    "    multi_df = pd.DataFrame(haps_multi).set_index(pos_multi.values)\n",
    "    multi_split_df = split_multialleles(multi_df)\n",
    "    \n",
    "    \n",
    "    ### load eff dataframe\n",
    "    print(\"loading df_effects for region\")\n",
    "    transcripts = ag3.geneset().query(\"type == 'exon' & contig == @contig & start > @start & end < @end\")['Parent'].unique()\n",
    "    snp_freq_dfs = []\n",
    "    for transcript_id in transcripts:\n",
    "        snp_allele_freqs_df = ag3.snp_effects(\n",
    "            transcript=transcript_id, \n",
    "        )\n",
    "        snp_freq_dfs.append(snp_allele_freqs_df)\n",
    "\n",
    "    df_effects = pd.concat(snp_freq_dfs)\n",
    "    \n",
    "    ## remap haps\n",
    "    print(\"remapping biallelic haplotypes\")\n",
    "    haps_remapped, remap_pos = locusPocus.remap_haplo_alleles(haps_bial, \n",
    "                                            pos_bial, \n",
    "                                            transcript=f\"{contig}:{start}-{end}\", \n",
    "                                            sample_set=cohorts, \n",
    "                                            metaquery=metaquery)\n",
    "    bial_df = pd.DataFrame(haps_remapped).set_index(remap_pos.values)\n",
    "    haps_df = pd.concat([bial_df, multi_split_df], axis=0).sort_index()\n",
    "    \n",
    "    print(\"filtering to seg sites\")\n",
    "    seg_bool = haps_df.apply(lambda x: len(np.unique(x)) > 1, axis=1)\n",
    "    haps_df = haps_df[seg_bool]\n",
    "    \n",
    "    print(\"intersecting with df_effects\")\n",
    "    ### intersecting df_effects\n",
    "    pos = allel.SortedIndex(haps_df.index.values)\n",
    "    hap_pos_bool, df_effects_bool = pos.locate_intersection(df_effects['position'])\n",
    "    df_effects = df_effects[df_effects_bool]\n",
    "    hap_remap_positions = pos[hap_pos_bool]\n",
    "    haps_df = haps_df[hap_pos_bool]\n",
    "    \n",
    "    print(\"extracting aa change info for each SNP\")\n",
    "    ### get relevant aa change for each snp \n",
    "    aa_change_list = []\n",
    "    non_synon_bool= []\n",
    "    for pos, row in haps_df.iterrows():\n",
    "        df_eff = df_effects.query(\"position == @pos\")\n",
    "        alleles = np.unique(row)\n",
    "        alt = alleles[1]-1\n",
    "\n",
    "        eff = df_eff['effect'].to_numpy()[alt]\n",
    "        if eff != 'NON_SYNONYMOUS_CODING':\n",
    "            aa_change = \"\"\n",
    "            non_synon_bool.append(False)\n",
    "        elif eff == 'NON_SYNONYMOUS_CODING':\n",
    "            aa_change = df_eff['aa_change'].to_numpy()[alt]\n",
    "            non_synon_bool.append(True)\n",
    "        aa_change_list.append(aa_change)\n",
    "        \n",
    "    haps_df.loc[:, 'aa_change'] = aa_change_list\n",
    "    haps_df = haps_df.set_index(\"aa_change\", append=True)\n",
    "    return(haps_df, non_synon_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "7edfe8d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotypes loaded\n",
      "only two alleles = 28545862\n",
      "only two alleles = 28545945\n",
      "only two alleles = 28546024\n",
      "only two alleles = 28546029\n",
      "only two alleles = 28546185\n",
      "only two alleles = 28546335\n",
      "only two alleles = 28546340\n",
      "only two alleles = 28546376\n",
      "only two alleles = 28546460\n",
      "only two alleles = 28546587\n",
      "only two alleles = 28546588\n",
      "only two alleles = 28546589\n",
      "only two alleles = 28546634\n",
      "only two alleles = 28546656\n",
      "only two alleles = 28546660\n",
      "only two alleles = 28546810\n",
      "only two alleles = 28547166\n",
      "only two alleles = 28547522\n",
      "only two alleles = 28547729\n",
      "only two alleles = 28547744\n",
      "only two alleles = 28547759\n",
      "only two alleles = 28547780\n",
      "loading df_effects for region\n",
      "remapping biallelic haplotypes\n",
      "filtering to seg sites\n",
      "intersecting with df_effects\n",
      "extracting aa change info for each SNP\n"
     ]
    }
   ],
   "source": [
    "haps_df, non_synon_bool = load_multiallelic_haplotypes(path_to_multi_vcf=\"../../results/phasing/coeae1f.phasedMulti.vcf\",\n",
    "                                                      sample_sets=cohorts, contig=contig, start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6cd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
