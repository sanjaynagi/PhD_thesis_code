{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probe\n",
    "import scipy\n",
    "\n",
    "# vectorized haversine function\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "    \"\"\"\n",
    "    slightly modified version: of http://stackoverflow.com/a/29546836/2901002\n",
    "\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees or in radians)\n",
    "\n",
    "    All (lat, lon) coordinates must have numeric dtypes and be of equal length.\n",
    "\n",
    "    \"\"\"\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigs = ['2L', '2R', '3R', '3L', 'X']\n",
    "metadata = pd.read_csv(\"../../config/metadata.tsv\", sep=\"\\t\")\n",
    "dblton = pd.read_csv(\"../../results/f2variantPairs.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2Haps = {}\n",
    "for contig in contigs:\n",
    "    f2Haps[contig] = pd.read_csv(f\"../../results/f2variants/f2HapLengths.{contig}.tsv\", sep=\"\\t\", index_col=0)\n",
    "    f2Haps[contig]['contig'] = contig\n",
    "    f2Haps[contig]['size'] = f2Haps[contig]['end'] - f2Haps[contig]['start']\n",
    " \n",
    "f2df = pd.concat(f2Haps, axis=0).reset_index(drop=True)\n",
    "f2haps = dblton.merge(f2df.rename(columns={'dblton_pos':'pos'}))\n",
    "f2haps['distance'] = haversine(f2haps['latitude'], f2haps['longitude'], f2haps['latitude2'], f2haps['longitude2'])\n",
    "\n",
    "#f2haps['dist_bin'] = pd.cut(f2haps['distance'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.linregress(f2haps['distance'], f2haps['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps.query(\"size < 100_0000\")['size'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contig in contigs:\n",
    "    print(contig, f2Haps[contig]['size'].describe().apply(lambda x: format(x, 'f')))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contig in contigs:\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=f2Haps[contig]['start'], y=f2Haps[contig]['size'], alpha=0.3)\n",
    "    plt.title(contig)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there does seem to be an excess of large f2 haplotypes around the centromeres - regions of low recombination - makes sense. Theres also a clear spike at Gste2? Though no spike at VGSC. What if we try calculate doubleton density in windows? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_density(pos, window_size, title):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(30, 10))\n",
    "    sns.despine(ax=ax, offset=5)\n",
    "    y, windows = allel.windowed_count(pos, size=window_size)\n",
    "    x = np.mean(windows, axis=1)\n",
    "    ax.plot(x, y/window_size)\n",
    "    ax.set_ylabel('Density (bp$^{-1}$)')\n",
    "    ax.set_xlabel('Position (bp)')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "for contig in contigs:\n",
    "    dbdf = dblton.query(\"contig == @contig\")\n",
    "    plot_density(dbdf['pos'], 50000, contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contig in contigs:\n",
    "    df = f2Haps[contig]\n",
    "\n",
    "    midpoints = df['dblton_pos']\n",
    "    midpoints = allel.moving_statistic(midpoints, np.median, size=5000, step=1000) \n",
    "    sizes = allel.moving_statistic(df['size'], np.median, size=5000, step=1000)\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=midpoints, y=sizes, alpha=0.3)\n",
    "    plt.title(contig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = pd.read_csv(\"../../results/relatedness/ngsRelate.ag3_gaardian\", sep=\"\\t\")\n",
    "metadata['order'] = np.arange(0,len(metadata))\n",
    "n_dbltons = dblton.value_counts(['idx1', 'idx2']).to_frame().reset_index().rename(columns={0:'n_doubletons'})\n",
    "rel = rel.merge(metadata, left_on='a', right_on='order').merge(metadata, left_on='b', right_on='order')\n",
    "rel = rel.rename(columns={'a':'idx1', 'b':'idx2'})\n",
    "rel = rel.merge(n_dbltons)\n",
    "rel['spcomp'] = rel['species_gambiae_coluzzii_x'] + rel['species_gambiae_coluzzii_y']\n",
    "rel = rel.query(\"spcomp == 'coluzziicoluzzii' | spcomp == 'gambiaegambiae'\")\n",
    "\n",
    "## distance column \n",
    "rel['distance'] = haversine(rel['latitude_y'], rel['longitude_y'], rel['latitude_x'], rel['longitude_x'])\n",
    "totf2HapLength = f2haps.groupby(['idx1','idx2']).agg({'size':'sum'}).reset_index()\n",
    "rel = rel.merge(totf2HapLength)\n",
    "\n",
    "\n",
    "rel['kinship'] = np.select(\n",
    "    [\n",
    "        rel['KING'].between(-1, 0.0442, inclusive='both'), \n",
    "        rel['KING'].between(0.0443, 0.0884, inclusive='both'),\n",
    "        rel['KING'].between(0.0885, 0.177, inclusive='both'),\n",
    "        rel['KING'].between(0.178, 0.354, inclusive='both'),\n",
    "        rel['KING'].between(0.355, 0.5, inclusive='both')\n",
    "    ], \n",
    "    [\n",
    "        'Unrelated', \n",
    "        '3rd-Degree',\n",
    "        '2nd-Degree',\n",
    "        '1st Degree (full sib)',\n",
    "        'Dup/Twin'\n",
    "    ], \n",
    "    default='Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.query(\"KING < -0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps['dist_bins'] = pd.cut(f2haps['distance'], bins=4, labels=['0-17km', '17-34km', '34-51km', '51-70km'])\n",
    "f2haps['size_log'] = np.log(f2haps['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2hapmean_dict = f2haps.groupby(\"dist_bins\").agg({'size_log':'median'}).reset_index(drop=True).to_dict()\n",
    "f2hapmean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f2haps[['size_log', 'dist_bins']].rename(columns={'dist_bins':'g', 'size_log':'x'})\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\n",
    "g = sns.FacetGrid(df, row=\"g\", hue=\"g\", aspect=15, height=2, palette=pal)\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"x\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# flatten axes into a 1-d array\n",
    "axes = g.axes.flatten()\n",
    "\n",
    "# iterate through the axes\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.axvline(f2hapmean_dict['size_log'][i], ls='--', c='black')\n",
    "\n",
    "\n",
    "g.map(label, \"x\")\n",
    "g.set_xlabels(\"log distribution of f2 haplotype size\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.25)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,10])\n",
    "sns.scatterplot(data=rel.query(\"KING > -0.2\"), x='distance', y='KING', hue='kinship', alpha=0.95, s=120, linewidth=0.4, edgecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=[14,10])\n",
    "sns.scatterplot(data=rel, x='distance', y='n_doubletons', hue='kinship', alpha=0.8, s=120, linewidth=0.4, edgecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.figure(figsize=[14,10])\n",
    "sns.scatterplot(x=rel['distance'], y=rel['n_doubletons'], alpha=0.95, s=120, hue=rel['kinship'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps['size'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.query(\"KING > 0.177\")[['location2_y', 'location2_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps.query(\"size > 10_000_000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps['dist_bins'] = pd.cut(f2haps['distance'], bins=7, labels=['0-10km', '10-20km', '20-30km', '30-40km', '40-50km', '50-60km', '60-70km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps['size_log'] = np.log2(f2haps['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2haps.groupby('dist_bins').agg({'size':'median'}).to_csv(\"f2_hap_medians.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=f2haps, x='size_log', hue='dist_bins', kind='kde', palette='tab10', rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=f2haps.query(\"size < 300_000 & size > 10_000\"), x='size', hue='dist_bins', kind='kde', palette='tab10', rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2s = rel.query(\"KING > 0.0884 & KING < 0.177\")\n",
    "rel2s[['KING','distance', 'location2_y', 'location2_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.query(\"KING > 0.0442 & KING < 0.0884\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.query(\"KING < 0.0442 & species_gambiae_coluzzii_y == 'coluzzii'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel3s = rel.query(\"KING > 0.0442 & KING < 0.0884 &  species_gambiae_coluzzii_y == 'coluzzii'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel3s['distance'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "710100144729ec1057471750b60f3250df4296be7eb29e7e87fec32ed718ec4b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
